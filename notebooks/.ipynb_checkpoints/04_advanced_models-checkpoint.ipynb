{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe791e31-ae60-43b7-a2e6-9fcf95cffaf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4140818716.py, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 70\u001b[0;36m\u001b[0m\n\u001b[0;31m    eval_metric=\"logloss\",      # keep simple; we tune F1 on OOF afterwards\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# 04_advanced_models.ipynb — Jigsaw Agile Community Rules (XGBoost + submit)\n",
    "\n",
    "# Works locally and on Kaggle (Internet OFF). Produces /kaggle/working/submission.csv on Kaggle.\n",
    "\n",
    "# --- NEW IMPORTS (added 2025-09-24 for running 05_ensemble model) ---\n",
    "import os, json, gc, re\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# ========= 0) Imports & environment info =========\n",
    "\n",
    "import sys, os, glob, re, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"NumPy :\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "\n",
    "\n",
    "# ===== DEFINE X and y (REPLACEMENT BLOCK) =====\n",
    "import os, re, json, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 0) Where processed features live (keep as-is)\n",
    "PROC_DIR = \"data/processed\"\n",
    "\n",
    "# 1) Robust data path resolution\n",
    "def first_existing_dir(candidates, required_files=(\"train.csv\",\"test.csv\",\"sample_submission.csv\")):\n",
    "    for d in candidates:\n",
    "        try:\n",
    "            if d and all(os.path.exists(os.path.join(d, f)) for f in required_files):\n",
    "                return d\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "DATA_DIR_CANDIDATES = [\n",
    "    \"data/raw\",  # project-local default\n",
    "    \"/Users/michaelmaclennan/Documents/Learning & Education/2025-04 AI & ML/jigsaw-competition/data/raw\",  # your local absolute path\n",
    "    \"/kaggle/input/jigsaw-competition/data/raw\",  # if you staged a copy on Kaggle\n",
    "    \"/kaggle/input/jigsaw-toxic-comment-classification-challenge\",  # common Kaggle dataset root\n",
    "]\n",
    "\n",
    "DATA_DIR = first_existing_dir(DATA_DIR_CANDIDATES)\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find train/test/sample CSVs. \"\n",
    "        \"Either copy them to ./data/raw or update DATA_DIR_CANDIDATES with your absolute path.\"\n",
    "    )\n",
    "print(f\"[DATA] Using DATA_DIR = {DATA_DIR}\")\n",
    "\n",
    "train_path  = os.path.join(DATA_DIR, \"train.csv\")\n",
    "test_path   = os.path.join(DATA_DIR, \"test.csv\")\n",
    "sample_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",      # keep simple; we tune F1 on OOF afterwards\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")\n",
    "print(f\"[XGB] Using scale_pos_weight={scale_pos_weight:.3f} (pos_rate={pos_rate:.4f})\")\n",
    "\n",
    "# ========= 6) Build & validate submission =========\n",
    "# Ensure we have test_pred; if not, derive from test_prob (with tuned threshold if available)\n",
    "if \"test_pred\" not in globals():\n",
    "    if \"test_prob\" in globals():\n",
    "        thr = best_thr if \"best_thr\" in globals() else 0.5\n",
    "        test_pred = (test_prob >= thr).astype(int)\n",
    "        print(f\"[SUB] Derived test_pred from test_prob with thr={thr:.3f}\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Neither test_pred nor test_prob found. Run the model/test prediction cell first.\")\n",
    "\n",
    "# Ensure sample + names exist\n",
    "if \"sample\" not in globals():\n",
    "    sample = pd.read_csv(sample_path)\n",
    "if \"TARGET_OUT\" not in globals():\n",
    "    TARGET_OUT = sample.columns[1] if sample.shape[1] >= 2 else \"prediction\"\n",
    "if \"ID_COL\" not in globals():\n",
    "    ID_COL = sample.columns[0]\n",
    "\n",
    "# Build submission with exact columns/ordering as sample\n",
    "submission = sample.copy()\n",
    "submission[TARGET_OUT] = test_pred.astype(int)\n",
    "\n",
    "# Sanity checks\n",
    "errors = []\n",
    "if list(submission.columns) != list(sample.columns):\n",
    "    errors.append(\"Submission columns don't match sample exactly.\")\n",
    "if submission[TARGET_OUT].isna().any():\n",
    "    errors.append(\"Found NaNs in prediction column.\")\n",
    "if errors:\n",
    "    raise ValueError(\" | \".join(errors))\n",
    "\n",
    "# Save\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "sub_path = \"submissions/submission.csv\"\n",
    "submission.to_csv(sub_path, index=False)\n",
    "print(f\"[SUB] Wrote {sub_path} with shape {submission.shape}\")\n",
    "\n",
    "\n",
    "# ========= 6) Build & validate submission =========\n",
    "# Ensure we have test_pred; if not, derive from test_prob (with tuned threshold if available)\n",
    "if \"test_pred\" not in globals():\n",
    "    if \"test_prob\" in globals():\n",
    "        thr = best_thr if \"best_thr\" in globals() else 0.5\n",
    "        test_pred = (test_prob >= thr).astype(int)\n",
    "        print(f\"[SUB] Derived test_pred from test_prob with thr={thr:.3f}\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Neither test_pred nor test_prob found. Run the model/test prediction cell first.\")\n",
    "\n",
    "# Ensure sample + names exist\n",
    "if \"sample\" not in globals():\n",
    "    sample = pd.read_csv(sample_path)\n",
    "if \"TARGET_OUT\" not in globals():\n",
    "    TARGET_OUT = sample.columns[1] if sample.shape[1] >= 2 else \"prediction\"\n",
    "if \"ID_COL\" not in globals():\n",
    "    ID_COL = sample.columns[0]\n",
    "\n",
    "# Build submission with exact columns/ordering as sample\n",
    "submission = sample.copy()\n",
    "submission[TARGET_OUT] = test_pred.astype(int)\n",
    "\n",
    "# Sanity checks\n",
    "errors = []\n",
    "if list(submission.columns) != list(sample.columns):\n",
    "    errors.append(\"Submission columns don't match sample exactly.\")\n",
    "if submission[TARGET_OUT].isna().any():\n",
    "    errors.append(\"Found NaNs in prediction column.\")\n",
    "if errors:\n",
    "    raise ValueError(\" | \".join(errors))\n",
    "\n",
    "# Save\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "sub_path = \"submissions/submission.csv\"\n",
    "submission.to_csv(sub_path, index=False)\n",
    "print(f\"[SUB] Wrote {sub_path} with shape {submission.shape}\")\n",
    "\n",
    "\n",
    "for fold,(tr,va) in enumerate(skf.split(X_combined, y), 1):\n",
    "    print(f\"[XGB OOF] Fold {fold}/{N_FOLDS}\")\n",
    "    model = xgb.XGBClassifier(**params)  # reuse your 'params'\n",
    "    model.fit(X_combined[tr], y[tr], eval_set=[(X_combined[va], y[va])],\n",
    "              verbose=False, early_stopping_rounds=50)\n",
    "    oof_prob[va] = model.predict_proba(X_combined[va])[:,1]\n",
    "    test_prob_folds.append(model.predict_proba(X_test)[:,1])\n",
    "\n",
    "test_prob = np.mean(np.column_stack(test_prob_folds), axis=1)\n",
    "\n",
    "# Save files for ensembling\n",
    "pd.DataFrame({\"row_id\": train_ids, \"prob\": oof_prob}).to_csv(\"results/oof/xgb_tfidf_feats_oof.csv\", index=False)\n",
    "pd.DataFrame({\"row_id\": test_ids,  \"prob\": test_prob}).to_csv(\"results/test_probs/xgb_tfidf_feats_test.csv\", index=False)\n",
    "print(\"Saved OOF/test probs for XGB → results/oof/xgb_tfidf_feats_oof.csv & results/test_probs/xgb_tfidf_feats_test.csv\")\n",
    "\n",
    "# Update results/models.json so 05_ensemble can weight models by val_f1\n",
    "import json, os\n",
    "meta_path = \"results/models.json\"\n",
    "model_key = \"xgb_tfidf_feats\"\n",
    "try:\n",
    "    meta = json.load(open(meta_path)) if os.path.exists(meta_path) else {}\n",
    "except Exception:\n",
    "    meta = {}\n",
    "# If file was a list, coerce to dict keyed by model\n",
    "if isinstance(meta, list):\n",
    "    meta = {d[\"model\"]: d for d in meta if isinstance(d, dict) and \"model\" in d}\n",
    "meta[model_key] = {\"val_f1\": float(val_f1)}\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(f\"Logged {model_key} val_f1={val_f1:.4f} → results/models.json\")\n",
    "\n",
    "\n",
    "# ========= 6) Build & validate submission =========\n",
    "submission = sample.copy()\n",
    "submission[TARGET_OUT] = test_pred.astype(int)\n",
    "\n",
    "errors = []\n",
    "if list(submission.columns) != list(sample.columns):\n",
    "    errors.append(f\"Columns mismatch. Expected {list(sample.columns)}, got {list(submission.columns)}\")\n",
    "if len(submission) != len(sample):\n",
    "    errors.append(f\"Row count mismatch. Expected {len(sample)}, got {len(submission)}\")\n",
    "if not submission[ID_COL].equals(sample[ID_COL]):\n",
    "    if set(submission[ID_COL]) != set(sample[ID_COL]):\n",
    "        missing = list(sorted(set(sample[ID_COL]) - set(submission[ID_COL])))[:5]\n",
    "        extra   = list(sorted(set(submission[ID_COL]) - set(sample[ID_COL])))[:5]\n",
    "        errors.append(f\"ID set differs. Missing: {missing} | Extra: {extra}\")\n",
    "    else:\n",
    "        errors.append(\"ID order differs from sample. Must match sample_submission order.\")\n",
    "if submission[TARGET_OUT].isna().any():\n",
    "    errors.append(\"Target has NaNs.\")\n",
    "u = set(np.unique(submission[TARGET_OUT]))\n",
    "if not u.issubset({0,1}):\n",
    "    errors.append(f\"Target invalid values {sorted(u)}; must be 0/1.\")\n",
    "\n",
    "if errors:\n",
    "    print(\"❌ Submission invalid:\")\n",
    "    for e in errors: print(\" -\", e)\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# ========= 7) Save submission (Kaggle + local) =========\n",
    "if IS_KAGGLE:\n",
    "    submission.to_csv(OUT_KAGGLE, index=False)\n",
    "    print(f\"✅ Saved Kaggle file: {OUT_KAGGLE}\")\n",
    "submission.to_csv(OUT_LOCAL, index=False)\n",
    "print(f\"✅ Saved local copy : {OUT_LOCAL}\")\n",
    "\n",
    "print(f\"\\nModel used: {'XGBoost' if use_xgb else 'LogisticRegression'}\")\n",
    "print(f\"Validation F1 (macro): {val_f1:.4f} at threshold {best_threshold:.3f}\")\n",
    "print(\"Final submission head:\\n\", submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38177072-36e2-43ed-bbdf-ccb675b1c0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
