{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe791e31-ae60-43b7-a2e6-9fcf95cffaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]\n",
      "NumPy : 1.26.4\n",
      "Pandas: 2.2.3\n",
      "[DATA] Using DATA_DIR = /Users/michaelmaclennan/Documents/Learning & Education/2025-04 AI & ML/jigsaw-competition/data/raw\n",
      "[PROC] Loaded processed features: X=(2029, 9966), y=(2029,), X_test=(10, 9966)\n",
      "Loaded processed features: X shape=(2029, 9966), y shape=(2029,)\n",
      "Train/valid shapes: (1623, 9966) (406, 9966) (1623,) (406,)\n",
      "Pos rate (train/valid): 0.5083 0.5074\n",
      "Using XGBoost …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (val) = 0.440 | Val F1(macro) = 0.7373\n",
      "Validation confusion matrix:\n",
      " [[134  66]\n",
      " [ 40 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7701    0.6700    0.7166       200\n",
      "           1     0.7155    0.8058    0.7580       206\n",
      "\n",
      "    accuracy                         0.7389       406\n",
      "   macro avg     0.7428    0.7379    0.7373       406\n",
      "weighted avg     0.7424    0.7389    0.7376       406\n",
      "\n",
      "[XGB OOF] Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB OOF] Fold 2/5\n",
      "[XGB OOF] Fold 3/5\n",
      "[XGB OOF] Fold 4/5\n",
      "[XGB OOF] Fold 5/5\n",
      "Saved OOF/test probs for XGB → results/oof/xgb_tfidf_feats_oof.csv & results/test_probs/xgb_tfidf_feats_test.csv\n",
      "[LR OOF] Fold 1/5\n",
      "[LR OOF] Fold 2/5\n",
      "[LR OOF] Fold 3/5\n",
      "[LR OOF] Fold 4/5\n",
      "[LR OOF] Fold 5/5\n",
      "[LR OOF] Best OOF F1=0.7685 at thr=0.445\n",
      "[LR SAVE] Wrote results/oof/logreg_tfidf_feats_oof.csv and results/test_probs/logreg_tfidf_feats_test.csv\n",
      "[LR SAVE] Logged logreg_tfidf_feats val_f1=0.7685 → results/models.json\n",
      "Logged xgb_tfidf_feats val_f1=0.7685 → results/models.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1216: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1216: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1216: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1216: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1216: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TARGET_OUT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 486\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# ========= 6) Build & validate submission =========\u001b[39;00m\n\u001b[1;32m    485\u001b[0m submission \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 486\u001b[0m submission[TARGET_OUT] \u001b[38;5;241m=\u001b[39m test_pred\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    488\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(submission\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(sample\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TARGET_OUT' is not defined"
     ]
    }
   ],
   "source": [
    "# 04_advanced_models.ipynb — Jigsaw Agile Community Rules (XGBoost + submit)\n",
    "\n",
    "# Works locally and on Kaggle (Internet OFF). Produces /kaggle/working/submission.csv on Kaggle.\n",
    "\n",
    "# --- NEW IMPORTS (added 2025-09-24 for running 05_ensemble model) ---\n",
    "import sys, os, glob, re, warnings\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "#\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"NumPy :\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "\n",
    "\n",
    "# ===== DEFINE X and y (REPLACEMENT BLOCK) =====\n",
    "import os, re, json, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 0) Where processed features live (keep as-is)\n",
    "PROC_DIR = \"data/processed\"\n",
    "\n",
    "# 1) Robust data path resolution\n",
    "def first_existing_dir(candidates, required_files=(\"train.csv\",\"test.csv\",\"sample_submission.csv\")):\n",
    "    for d in candidates:\n",
    "        try:\n",
    "            if d and all(os.path.exists(os.path.join(d, f)) for f in required_files):\n",
    "                return d\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "DATA_DIR_CANDIDATES = [\n",
    "    \"data/raw\",  # project-local default\n",
    "    \"/Users/michaelmaclennan/Documents/Learning & Education/2025-04 AI & ML/jigsaw-competition/data/raw\",  # your local absolute path\n",
    "    \"/kaggle/input/jigsaw-competition/data/raw\",  # if you staged a copy on Kaggle\n",
    "    \"/kaggle/input/jigsaw-toxic-comment-classification-challenge\",  # common Kaggle dataset root\n",
    "]\n",
    "\n",
    "DATA_DIR = first_existing_dir(DATA_DIR_CANDIDATES)\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find train/test/sample CSVs. \"\n",
    "        \"Either copy them to ./data/raw or update DATA_DIR_CANDIDATES with your absolute path.\"\n",
    "    )\n",
    "print(f\"[DATA] Using DATA_DIR = {DATA_DIR}\")\n",
    "\n",
    "train_path  = os.path.join(DATA_DIR, \"train.csv\")\n",
    "test_path   = os.path.join(DATA_DIR, \"test.csv\")\n",
    "sample_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# 2) Try processed features; otherwise build TF-IDF from raw\n",
    "X, y = None, None\n",
    "try:\n",
    "    X = joblib.load(os.path.join(PROC_DIR, \"X_tfidf.pkl\"))\n",
    "    y = joblib.load(os.path.join(PROC_DIR, \"y.pkl\"))\n",
    "    X_test_full = joblib.load(os.path.join(PROC_DIR, \"X_test_tfidf.pkl\"))\n",
    "    print(f\"[PROC] Loaded processed features: X={X.shape}, y={y.shape}, X_test={X_test_full.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"[PROC] Processed features not found; will build TF-IDF from raw…\", e)\n",
    "    train_df  = pd.read_csv(train_path)\n",
    "    test_df   = pd.read_csv(test_path)\n",
    "    sample    = pd.read_csv(sample_path)\n",
    "\n",
    "    # Heuristics to find ID/TEXT/TARGET columns\n",
    "    id_candidates = [c for c in train_df.columns if \"id\" in c.lower() or \"row\" in c.lower()]\n",
    "    ID_COL = id_candidates[0] if id_candidates else train_df.columns[0]\n",
    "\n",
    "    text_candidates = [c for c in train_df.columns if train_df[c].dtype == \"object\"]\n",
    "    pref = [c for c in text_candidates if c.lower() in {\"text\",\"comment_text\",\"content\",\"message\"}]\n",
    "    TEXT_COL = pref[0] if pref else (text_candidates[0] if text_candidates else None)\n",
    "    if TEXT_COL is None:\n",
    "        raise ValueError(\"Could not detect a TEXT column. Set TEXT_COL manually.\")\n",
    "\n",
    "    num_cols = [c for c in train_df.columns if pd.api.types.is_numeric_dtype(train_df[c]) and c != ID_COL]\n",
    "    # Prefer common binary label names; otherwise find any {0,1} column\n",
    "    for cand in [\"label\",\"target\",\"toxic\",\"is_toxic\"]:\n",
    "        if cand in train_df.columns and cand in num_cols:\n",
    "            TARGET_COL = cand\n",
    "            break\n",
    "    else:\n",
    "        TARGET_COL = None\n",
    "        for c in num_cols:\n",
    "            vals = set(pd.Series(train_df[c]).dropna().unique().tolist())\n",
    "            if vals.issubset({0,1}):\n",
    "                TARGET_COL = c\n",
    "                break\n",
    "        if TARGET_COL is None:\n",
    "            raise ValueError(\"Could not detect a binary TARGET column. Set TARGET_COL manually.\")\n",
    "\n",
    "    print(f\"[COLUMNS] ID_COL={ID_COL} | TEXT_COL={TEXT_COL} | TARGET_COL={TARGET_COL}\")\n",
    "\n",
    "    def clean_text(s):\n",
    "        if pd.isna(s): return \"\"\n",
    "        s = str(s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "        return s.strip()\n",
    "\n",
    "    train_df[TEXT_COL] = train_df[TEXT_COL].map(clean_text)\n",
    "    test_df[TEXT_COL]  = test_df[TEXT_COL].map(clean_text)\n",
    "\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=15000, min_df=2)\n",
    "    X_tr_text = tfidf.fit_transform(train_df[TEXT_COL].values)\n",
    "    X_te_text = tfidf.transform(test_df[TEXT_COL].values)\n",
    "\n",
    "    # Optional: stack numeric aux features saved by 03 (if present)\n",
    "    aux_tr_path = os.path.join(PROC_DIR, \"aux_train.npy\")\n",
    "    aux_te_path = os.path.join(PROC_DIR, \"aux_test.npy\")\n",
    "    if os.path.exists(aux_tr_path) and os.path.exists(aux_te_path):\n",
    "        aux_tr = np.load(aux_tr_path); aux_te = np.load(aux_te_path)\n",
    "        if aux_tr.ndim == 1: aux_tr = aux_tr[:, None]\n",
    "        if aux_te.ndim == 1: aux_te = aux_te[:, None]\n",
    "        X = sparse.hstack([X_tr_text, sparse.csr_matrix(aux_tr)], format=\"csr\")\n",
    "        X_test_full = sparse.hstack([X_te_text, sparse.csr_matrix(aux_te)], format=\"csr\")\n",
    "        print(f\"[FEATS] TF-IDF + AUX → X={X.shape}, test={X_test_full.shape}\")\n",
    "    else:\n",
    "        X = X_tr_text\n",
    "        X_test_full = X_te_text\n",
    "        print(f\"[FEATS] TF-IDF only → X={X.shape}, test={X_test_full.shape}\")\n",
    "\n",
    "    y = train_df[TARGET_COL].astype(int).values\n",
    "\n",
    "    # Save for reuse (optional)\n",
    "    os.makedirs(PROC_DIR, exist_ok=True)\n",
    "    try:\n",
    "        joblib.dump(X, os.path.join(PROC_DIR, \"X_tfidf.pkl\"))\n",
    "        joblib.dump(y, os.path.join(PROC_DIR, \"y.pkl\"))\n",
    "        joblib.dump(X_test_full, os.path.join(PROC_DIR, \"X_test_tfidf.pkl\"))\n",
    "        joblib.dump(tfidf, os.path.join(PROC_DIR, \"tfidf_vectorizer.pkl\"))\n",
    "        joblib.dump({\"ID_COL\":ID_COL,\"TEXT_COL\":TEXT_COL,\"TARGET_COL\":TARGET_COL}, os.path.join(PROC_DIR, \"column_meta.pkl\"))\n",
    "        print(\"[PROC] Saved TF-IDF features to data/processed/\")\n",
    "    except Exception as e2:\n",
    "        print(\"[PROC] Skipping joblib dump:\", e2)\n",
    "\n",
    "# --- alias for downstream cells expecting `X_test` ---\n",
    "X_combined = X\n",
    "X_test = X_test_full\n",
    "\n",
    "\n",
    "assert X.shape[0] == len(y), \"X and y length mismatch\"\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "# 1) Try to load prebuilt matrices from 03_feature_engineering (if available)\n",
    "X, y = None, None\n",
    "try:\n",
    "    X = joblib.load(os.path.join(PROC_DIR, \"X_tfidf.pkl\"))\n",
    "    y = joblib.load(os.path.join(PROC_DIR, \"y.pkl\"))\n",
    "    print(f\"Loaded processed features: X shape={X.shape}, y shape={y.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"Processed features not found, will build TF-IDF from raw CSV…\", e)\n",
    "\n",
    "# 2) If not found, build from raw CSV now\n",
    "if X is None or y is None:\n",
    "    train_path = os.path.join(DATA_DIR, \"train.csv\")\n",
    "    test_path  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "    sample_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "    train_df  = pd.read_csv(train_path)\n",
    "    test_df   = pd.read_csv(test_path)\n",
    "    sample    = pd.read_csv(sample_path)\n",
    "\n",
    "    # Heuristics to find text/label/id cols\n",
    "    # (Adjust if your column names are different)\n",
    "    id_candidates = [c for c in train_df.columns if \"id\" in c.lower() or \"row\" in c.lower()]\n",
    "    ID_COL = id_candidates[0] if id_candidates else train_df.columns[0]\n",
    "\n",
    "    # pick the first long string column as text\n",
    "    text_candidates = [c for c in train_df.columns if train_df[c].dtype == \"object\"]\n",
    "    # prefer common names if present\n",
    "    pref = [c for c in text_candidates if c.lower() in {\"text\", \"comment_text\", \"content\", \"message\"}]\n",
    "    TEXT_COL = pref[0] if pref else (text_candidates[0] if text_candidates else None)\n",
    "    if TEXT_COL is None:\n",
    "        raise ValueError(\"Could not detect a TEXT column. Please set TEXT_COL manually.\")\n",
    "\n",
    "    # pick a binary numeric label column\n",
    "    num_cols = [c for c in train_df.columns if pd.api.types.is_numeric_dtype(train_df[c])]\n",
    "    # exclude typical non-label numerics like id-like columns\n",
    "    blacklist = {ID_COL}\n",
    "    num_cols = [c for c in num_cols if c not in blacklist]\n",
    "    # try common names first\n",
    "    for cand in [\"label\", \"target\", \"toxic\", \"is_toxic\"]:\n",
    "        if cand in train_df.columns and cand in num_cols:\n",
    "            TARGET_COL = cand\n",
    "            break\n",
    "    else:\n",
    "        # fallback: any numeric column with only {0,1}\n",
    "        TARGET_COL = None\n",
    "        for c in num_cols:\n",
    "            vals = set(pd.Series(train_df[c]).dropna().unique().tolist())\n",
    "            if vals.issubset({0,1}):\n",
    "                TARGET_COL = c\n",
    "                break\n",
    "        if TARGET_COL is None:\n",
    "            raise ValueError(\"Could not detect a binary TARGET column. Please set TARGET_COL manually.\")\n",
    "\n",
    "    print(f\"ID_COL={ID_COL} | TEXT_COL={TEXT_COL} | TARGET_COL={TARGET_COL}\")\n",
    "\n",
    "    # basic clean\n",
    "    def clean_text(s):\n",
    "        if pd.isna(s): return \"\"\n",
    "        s = str(s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "        return s.strip()\n",
    "\n",
    "    train_df[TEXT_COL] = train_df[TEXT_COL].map(clean_text)\n",
    "    test_df[TEXT_COL]  = test_df[TEXT_COL].map(clean_text)\n",
    "\n",
    "    # TF-IDF features (1,2)-grams as per your earlier setup\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=15000, min_df=2)\n",
    "    X_tr_text = tfidf.fit_transform(train_df[TEXT_COL].values)\n",
    "    X_te_text = tfidf.transform(test_df[TEXT_COL].values)\n",
    "\n",
    "    # If you have numeric aux features from 03 (e.g., lengths, counts), try to load & hstack\n",
    "    aux_tr_path = os.path.join(PROC_DIR, \"aux_train.npy\")\n",
    "    aux_te_path = os.path.join(PROC_DIR, \"aux_test.npy\")\n",
    "    if os.path.exists(aux_tr_path) and os.path.exists(aux_te_path):\n",
    "        aux_tr = np.load(aux_tr_path)\n",
    "        aux_te = np.load(aux_te_path)\n",
    "        # ensure 2D\n",
    "        if aux_tr.ndim == 1: aux_tr = aux_tr[:, None]\n",
    "        if aux_te.ndim == 1: aux_te = aux_te[:, None]\n",
    "        X = sparse.hstack([X_tr_text, sparse.csr_matrix(aux_tr)], format=\"csr\")\n",
    "        X_test_full = sparse.hstack([X_te_text, sparse.csr_matrix(aux_te)], format=\"csr\")\n",
    "        print(f\"HSTACK with aux feats → X shape={X.shape}, test shape={X_test_full.shape}\")\n",
    "    else:\n",
    "        X = X_tr_text\n",
    "        X_test_full = X_te_text\n",
    "        print(f\"TF-IDF only → X shape={X.shape}, test shape={X_test_full.shape}\")\n",
    "\n",
    "    y = train_df[TARGET_COL].astype(int).values\n",
    "\n",
    "    # Save for reuse (optional)\n",
    "    os.makedirs(PROC_DIR, exist_ok=True)\n",
    "    try:\n",
    "        joblib.dump(X, os.path.join(PROC_DIR, \"X_tfidf.pkl\"))\n",
    "        joblib.dump(y, os.path.join(PROC_DIR, \"y.pkl\"))\n",
    "        joblib.dump(X_test_full, os.path.join(PROC_DIR, \"X_test_tfidf.pkl\"))\n",
    "        joblib.dump(tfidf, os.path.join(PROC_DIR, \"tfidf_vectorizer.pkl\"))\n",
    "    except Exception as e:\n",
    "        print(\"Skipping joblib dump:\", e)\n",
    "\n",
    "# Small sanity check\n",
    "assert X.shape[0] == len(y), \"X and y length mismatch\"\n",
    "# =======================================================================\n",
    "\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train/valid shapes:\", X_tr.shape, X_va.shape, y_tr.shape, y_va.shape)\n",
    "print(\"Pos rate (train/valid):\", y_tr.mean().round(4), y_va.mean().round(4))\n",
    "\n",
    "\n",
    "# Preferred: XGBoost with early stopping; Fallback: Logistic Regression\n",
    "use_xgb = True\n",
    "best_threshold = 0.5\n",
    "val_f1 = None\n",
    "\n",
    "try:\n",
    "    print(\"Using XGBoost …\")\n",
    "    xgb_params = dict(\n",
    "        max_depth=8,\n",
    "        learning_rate=0.07,\n",
    "        n_estimators=800,              # large cap; early stopping will trim\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.9,\n",
    "        min_child_weight=1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    # Probabilities and dynamic threshold for F1(macro)\n",
    "    va_prob = model.predict_proba(X_va)[:, 1]\n",
    "    # Scan thresholds to maximise macro-F1 on validation\n",
    "    thr_grid = np.linspace(0.2, 0.8, 61)  # coarse but fine for small set\n",
    "    f1s = []\n",
    "    for t in thr_grid:\n",
    "        f1s.append(f1_score(y_va, (va_prob >= t).astype(int), average=\"macro\"))\n",
    "    best_idx = int(np.argmax(f1s))\n",
    "    best_threshold = float(thr_grid[best_idx])\n",
    "    val_f1 = float(f1s[best_idx])\n",
    "    print(f\"Best threshold (val) = {best_threshold:.3f} | Val F1(macro) = {val_f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix at best threshold\n",
    "    y_pred_va = (va_prob >= best_threshold).astype(int)\n",
    "    print(\"Validation confusion matrix:\\n\", confusion_matrix(y_va, y_pred_va))\n",
    "    print(classification_report(y_va, y_pred_va, digits=4))\n",
    "\n",
    "    # Refit on ALL data with best n_estimators (best_iteration_) if available\n",
    "    best_n = getattr(model, \"best_iteration\", None)\n",
    "    if best_n is None:\n",
    "        best_n = getattr(model, \"best_ntree_limit\", None)\n",
    "    if best_n is None:\n",
    "        best_n = xgb_params[\"n_estimators\"]\n",
    "    else:\n",
    "        best_n = int(best_n) + 1\n",
    "\n",
    "    model_final = xgb.XGBClassifier(**{**xgb_params, \"n_estimators\": best_n})\n",
    "    model_final.fit(X, y, verbose=False)\n",
    "\n",
    "    # Predict test with tuned threshold\n",
    "    test_prob = model_final.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_prob >= best_threshold).astype(int)\n",
    "\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"XGBoost unavailable or errored ({e}). Falling back to Logistic Regression.\")\n",
    "    use_xgb = False\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l2\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=3000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    lr.fit(X_tr, y_tr)\n",
    "    va_prob = lr.predict_proba(X_va)[:, 1]\n",
    "    # threshold tuning\n",
    "    thr_grid = np.linspace(0.2, 0.8, 61)\n",
    "    f1s = [f1_score(y_va, (va_prob >= t).astype(int), average=\"macro\") for t in thr_grid]\n",
    "    best_idx = int(np.argmax(f1s))\n",
    "    best_threshold = float(thr_grid[best_idx])\n",
    "    val_f1 = float(f1s[best_idx])\n",
    "    print(f\"[LR] Best threshold (val) = {best_threshold:.3f} | Val F1(macro) = {val_f1:.4f}\")\n",
    "\n",
    "    y_pred_va = (va_prob >= best_threshold).astype(int)\n",
    "    print(\"Validation confusion matrix:\\n\", confusion_matrix(y_va, y_pred_va))\n",
    "    print(classification_report(y_va, y_pred_va, digits=4))\n",
    "\n",
    "    # Train on all & predict test\n",
    "    lr.fit(X, y)\n",
    "    test_prob = lr.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_prob >= best_threshold).astype(int)\n",
    "\n",
    "# === OOF + test probabilities for ensembling (XGBoost) ===\n",
    "import numpy as np, os, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "\n",
    "IS_KAGGLE = os.path.exists(\"/kaggle/input\")\n",
    "os.makedirs(\"results/oof\", exist_ok=True)\n",
    "os.makedirs(\"results/test_probs\", exist_ok=True)\n",
    "\n",
    "ID_COL = sample.columns[0]        # assumes you already loaded sample_submission.csv\n",
    "train_ids = train_df[ID_COL].values\n",
    "test_ids  = sample[ID_COL].values\n",
    "\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof_prob = np.zeros(len(train_df), dtype=float)\n",
    "test_prob_folds = []\n",
    "\n",
    "for fold,(tr,va) in enumerate(skf.split(X_combined, y), 1):\n",
    "    print(f\"[XGB OOF] Fold {fold}/{N_FOLDS}\")\n",
    "    model = xgb.XGBClassifier(**params)  # reuse your 'params'\n",
    "    model.fit(X_combined[tr], y[tr], eval_set=[(X_combined[va], y[va])],\n",
    "              verbose=False, early_stopping_rounds=50)\n",
    "    oof_prob[va] = model.predict_proba(X_combined[va])[:,1]\n",
    "    test_prob_folds.append(model.predict_proba(X_test)[:,1])\n",
    "\n",
    "test_prob = np.mean(np.column_stack(test_prob_folds), axis=1)\n",
    "\n",
    "# Save files for ensembling\n",
    "pd.DataFrame({\"row_id\": train_ids, \"prob\": oof_prob}).to_csv(\"results/oof/xgb_tfidf_feats_oof.csv\", index=False)\n",
    "pd.DataFrame({\"row_id\": test_ids,  \"prob\": test_prob}).to_csv(\"results/test_probs/xgb_tfidf_feats_test.csv\", index=False)\n",
    "print(\"Saved OOF/test probs for XGB → results/oof/xgb_tfidf_feats_oof.csv & results/test_probs/xgb_tfidf_feats_test.csv\")\n",
    "\n",
    "# === OOF + test probabilities for ensembling (Logistic Regression on TF-IDF) ===\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Preconditions: we rely on names already created earlier in 04:\n",
    "# X (csr_matrix), y (1D array), X_test (csr_matrix), train_df, sample, ID_COL\n",
    "for name in [\"X\",\"y\",\"X_test\",\"train_df\",\"sample\",\"ID_COL\"]:\n",
    "    if name not in globals():\n",
    "        raise RuntimeError(f\"Missing `{name}` — run the features/paths cells first.\")\n",
    "\n",
    "os.makedirs(\"results/oof\", exist_ok=True)\n",
    "os.makedirs(\"results/test_probs\", exist_ok=True)\n",
    "\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof_prob = np.zeros(X.shape[0], dtype=float)\n",
    "test_prob_folds = []\n",
    "\n",
    "# A solid baseline config for sparse TF-IDF (binary)\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    C=2.0,\n",
    "    solver=\"liblinear\",   # good for sparse, binary\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"[LR OOF] Fold {fold}/{N_FOLDS}\")\n",
    "    lr.fit(X[tr], y[tr])\n",
    "    oof_prob[va] = lr.predict_proba(X[va])[:, 1]\n",
    "    test_prob_folds.append(lr.predict_proba(X_test)[:, 1])\n",
    "\n",
    "test_prob = np.mean(np.column_stack(test_prob_folds), axis=1)\n",
    "\n",
    "# Tune threshold on OOF (use existing helper if present)\n",
    "def _tune_thr(y_true, p):\n",
    "    if \"tune_threshold\" in globals():\n",
    "        thr, f1 = tune_threshold(y_true, p, lo=0.25, hi=0.75, steps=201)\n",
    "        return float(thr), float(f1)\n",
    "    grid = np.linspace(0.25, 0.75, 201)\n",
    "    scores = [f1_score(y_true, (p >= t).astype(int)) for t in grid]\n",
    "    i = int(np.argmax(scores))\n",
    "    return float(grid[i]), float(scores[i])\n",
    "\n",
    "best_thr, val_f1 = _tune_thr(y, oof_prob)\n",
    "print(f\"[LR OOF] Best OOF F1={val_f1:.4f} at thr={best_thr:.3f}\")\n",
    "\n",
    "# Save for 05_ensemble\n",
    "oof_path   = \"results/oof/logreg_tfidf_feats_oof.csv\"\n",
    "test_path  = \"results/test_probs/logreg_tfidf_feats_test.csv\"\n",
    "pd.DataFrame({\"row_id\": train_df[ID_COL].values, \"prob\": oof_prob}).to_csv(oof_path, index=False)\n",
    "pd.DataFrame({\"row_id\": sample[ID_COL].values, \"prob\": test_prob}).to_csv(test_path, index=False)\n",
    "print(f\"[LR SAVE] Wrote {oof_path} and {test_path}\")\n",
    "\n",
    "# Log val_f1 so 05 can do weighted blends\n",
    "meta_path = \"results/models.json\"\n",
    "model_key = \"logreg_tfidf_feats\"\n",
    "try:\n",
    "    meta = json.load(open(meta_path)) if os.path.exists(meta_path) else {}\n",
    "except Exception:\n",
    "    meta = {}\n",
    "if isinstance(meta, list):\n",
    "    meta = {d[\"model\"]: d for d in meta if isinstance(d, dict) and \"model\" in d}\n",
    "meta[model_key] = {\"val_f1\": float(val_f1)}\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(f\"[LR SAVE] Logged {model_key} val_f1={val_f1:.4f} → results/models.json\")\n",
    "\n",
    "\n",
    "# Update results/models.json so 05_ensemble can weight models by val_f1\n",
    "import json, os\n",
    "meta_path = \"results/models.json\"\n",
    "model_key = \"xgb_tfidf_feats\"\n",
    "try:\n",
    "    meta = json.load(open(meta_path)) if os.path.exists(meta_path) else {}\n",
    "except Exception:\n",
    "    meta = {}\n",
    "# If file was a list, coerce to dict keyed by model\n",
    "if isinstance(meta, list):\n",
    "    meta = {d[\"model\"]: d for d in meta if isinstance(d, dict) and \"model\" in d}\n",
    "meta[model_key] = {\"val_f1\": float(val_f1)}\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(f\"Logged {model_key} val_f1={val_f1:.4f} → results/models.json\")\n",
    "\n",
    "\n",
    "# ========= 6) Build & validate submission =========\n",
    "submission = sample.copy()\n",
    "submission[TARGET_OUT] = test_pred.astype(int)\n",
    "\n",
    "errors = []\n",
    "if list(submission.columns) != list(sample.columns):\n",
    "    errors.append(f\"Columns mismatch. Expected {list(sample.columns)}, got {list(submission.columns)}\")\n",
    "if len(submission) != len(sample):\n",
    "    errors.append(f\"Row count mismatch. Expected {len(sample)}, got {len(submission)}\")\n",
    "if not submission[ID_COL].equals(sample[ID_COL]):\n",
    "    if set(submission[ID_COL]) != set(sample[ID_COL]):\n",
    "        missing = list(sorted(set(sample[ID_COL]) - set(submission[ID_COL])))[:5]\n",
    "        extra   = list(sorted(set(submission[ID_COL]) - set(sample[ID_COL])))[:5]\n",
    "        errors.append(f\"ID set differs. Missing: {missing} | Extra: {extra}\")\n",
    "    else:\n",
    "        errors.append(\"ID order differs from sample. Must match sample_submission order.\")\n",
    "if submission[TARGET_OUT].isna().any():\n",
    "    errors.append(\"Target has NaNs.\")\n",
    "u = set(np.unique(submission[TARGET_OUT]))\n",
    "if not u.issubset({0,1}):\n",
    "    errors.append(f\"Target invalid values {sorted(u)}; must be 0/1.\")\n",
    "\n",
    "if errors:\n",
    "    print(\"❌ Submission invalid:\")\n",
    "    for e in errors: print(\" -\", e)\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# ========= 7) Save submission (Kaggle + local) =========\n",
    "if IS_KAGGLE:\n",
    "    submission.to_csv(OUT_KAGGLE, index=False)\n",
    "    print(f\"✅ Saved Kaggle file: {OUT_KAGGLE}\")\n",
    "submission.to_csv(OUT_LOCAL, index=False)\n",
    "print(f\"✅ Saved local copy : {OUT_LOCAL}\")\n",
    "\n",
    "print(f\"\\nModel used: {'XGBoost' if use_xgb else 'LogisticRegression'}\")\n",
    "print(f\"Validation F1 (macro): {val_f1:.4f} at threshold {best_threshold:.3f}\")\n",
    "print(\"Final submission head:\\n\", submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38177072-36e2-43ed-bbdf-ccb675b1c0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
